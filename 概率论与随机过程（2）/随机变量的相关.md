## 随机变量的相关性

### 相关系数与协方差

**相关**描述两个随机变量之间的线性关系，即寻找 $Y \simeq \alpha X$ 的关系。为此，考虑**均方误差 (MSE)**：
$$
\text{MSE} = \mathbb{E}[(Y - \alpha X)^2]
$$
我们希望寻找 $\arg \min\limits_{\alpha} \text{MSE}$，因此令
$$
\frac{\partial \text{MSE}}{\partial \alpha} = \dfrac{\partial}{\partial \alpha} \mathbb{E}[(Y - \alpha X)^2] = 0
$$
直接**交换求导与求期望**两个微积分过程，得到
$$
\mathbb{E}[-2X(Y - \alpha X)] = 0 \quad \Longrightarrow \quad \alpha = \frac{\mathbb{E}[XY]}{\mathbb{E}[X^2]}
$$

> [!definition] 相关
> 两个随机变量 $X$ 和 $Y$ 之积的期望 $\mathbb{E}[XY]$ 即称为二者的**相关** (correlation)。

^c26c88

相关具有**双线性 (bilinear)** 性质，即对于任意常数 $a$、$b$，有
$$
\begin{cases}
\mathbb{E}[(aX_{1} + bX_{2})Y] = a\mathbb{E}[X_{1}Y] + b\mathbb{E}[X_{2}Y], \\
\mathbb{E}[X(aY_{1} + bY_{2})] = a\mathbb{E}[XY_{1}] + b\mathbb{E}[XY_{2}]
\end{cases}
$$

> [!definition] 协方差
> 两个随机变量 $X$ 和 $Y$ 的**协方差 (covariance)** 定义为
> $$
> \text{Cov}(X,Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]
> $$

显然，协方差也具有**双线性**性质，并且 $\text{Cov}(X,X) = \text{Var}(X)$。

> [!danger] 独立 (independence) 与相关 (correlation)
>
> + **独立**即两个随机变量 $X$ 和 $Y$ 满足 
> $$f_{X,Y}(x,y) = f_{X}(x)f_{Y}(y)$$
> + **相关**描述两个随机变量之间的线性关系，通常用**相关系数**来衡量，定义为

### 随机变量相关性的几何描述

考虑随机变量 $X$ 和 $Y$ 的**内积空间**，定义**内积**为
$$
\langle X, Y \rangle = \mathbb{E}[XY]
$$
则**范数**即为
$$
\|X\| = \sqrt{\langle X, X \rangle} = \sqrt{\mathbb{E}[X^2]}
$$
这样，$Y$ 在 $X$ 方向上的投影为
$$
\text{proj}_{X}Y = \frac{\langle X, Y \rangle}{\|X\|^2} X = \frac{\mathbb{E}[XY]}{\mathbb{E}[X^2]} X
$$
与前面通过最小化 MSE 得到的结果一致。

进一步地，考虑多个随机变量 $X_{1}, X_{2}, \ldots, X_{n}$，记 $Y$ 在这些变量张成的子空间上的投影为
$$
\text{proj}_{X_{1}, X_{2}, \ldots, X_{n}} Y = \alpha_{1} X_{1} + \alpha_{2} X_{2} + \cdots + \alpha_{n} X_{n} = \sum\limits_{i=1}^{n} \alpha_{i} X_{i} = \v{\alpha}^{\mathrm{T}} \v{X}
$$
于是 $\v{\alpha} = \arg\min\limits_{\vu{\alpha}} \mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X}) \big]$，而
$$
\begin{align}
\mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X})^2 \big] 
&= \mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X})^{\mathrm{T}}(Y-\vu{\alpha}^{\mathrm{T}}\v{X}) \big] \\
&= \mathbb{E} \big[(Y-\v{X}^{\mathrm{T}}\vu{\alpha})^{\mathrm{T}}(Y-\v{X}^{\mathrm{T}}\vu{\alpha}) \big] \\
&= \mathbb{E}[Y^2] - \mathbb{E} [Y^{\mathrm{T}} \v{X}^{\mathrm{T}}] \vu{\alpha} - \vu{\alpha}^{\mathrm{T}} \mathbb{E}[\v{X} Y] + \vu{\alpha}^{\mathrm{T}} \mathbb{E}[\v{X} \v{X}^{\mathrm{T}}] \vu{\alpha}
\end{align}
$$
对 $\vu{\alpha}$ 求梯度并令其为零，即
$$
\nabla_{\vu{\alpha}} \mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X})^2 \big] \Big|_{\vu{\alpha} = \v{\alpha}} = -\mathbb{E}[\v{X} Y] - \mathbb{E}[\v{X} Y] + 2 \mathbb{E}[\v{X} \v{X}^{\mathrm{T}}] \v{\alpha} = 0
$$
故
$$
\v{\alpha} = \big(\mathbb{E}[\v{X} \v{X}^{\mathrm{T}}]\big)^{-1} \mathbb{E}[\v{X} Y]
$$

## 多元相关的矩阵分析

对于一组随机变量 $\v{X} = \begin{pmatrix}X_{1} & X_{2} & \cdots & X_{n}\end{pmatrix}^{\mathrm{T}}$，其**相关矩阵 (correlation matrix)** 定义为
$$
\boldsymbol{R}_{\v{X}} = \mathbb{E} \left[\v{X} \v{X}^{\mathrm{H}}\right] = \begin{pmatrix}
\mathbb{E}[X_{1} X_{1}^{*}] & \mathbb{E}[X_{1} X_{2}^{*}] & \cdots & \mathbb{E}[X_{1} X_{n}^{*}] \\
\mathbb{E}[X_{2} X_{1}^{*}] & \mathbb{E}[X_{2} X_{2}^{*}] & \cdots & \mathbb{E}[X_{2} X_{n}^{*}] \\
\vdots & \vdots & \ddots & \vdots \\
\mathbb{E}[X_{n} X_{1}^{*}] & \mathbb{E}[X_{n} X_{2}^{*}] & \cdots & \mathbb{E}[X_{n} X_{n}^{*}]
\end{pmatrix} = \big( \mathbb{E}\left[ X_{i} X_{j} \right] \big)_{i,j} 
$$
显然，相关矩阵是**共轭对称**的，并且是**正定**的。

若将 $\v{X}$ 的元素下标 $n$ 视作时间，则 $\v{X}$ 可视作随机过程 $X(n)$ 的一个**样本向量 (sample vector)**，其相关矩阵为该随机过程在这些时刻的相关函数值，即
$$
\boldsymbol{R}_{\v{X}} = \big( R_{X}(i,j) \big)_{i,j}
$$

### 去相关 (decorrelation)

考虑线性变换 $\v{Y} = \boldsymbol{A} \v{X}$，其中 $\boldsymbol{A}$ 为方阵。我们希望找到  使得 $\v{Y}$ 的各分量**不相关**，即 $\mathbb{E}[Y_{i} Y_{j}^{*}] = 0$，$\forall i \neq j$，或
$$
\boldsymbol{R}_{\v{Y}} = \mathbb{E}\left[ \v{Y}\v{Y}^{\mathrm{H}} \right] = \mathbb{E}\left[ \boldsymbol{A} \v{X}\v{X}^{\mathrm{H}} \boldsymbol{A}^{\mathrm{H}} \right] = \boldsymbol{A} \boldsymbol{R}_{\v{X}} \boldsymbol{A}^{\mathrm{H}}
= \boldsymbol{\varLambda}_{\v{Y}}
$$
其中 $\boldsymbol{\varLambda}_{\v{Y}}$ 是对角阵。

因 $\boldsymbol{R}_{\v{X}}$ 是正定的，故其**特征值均非负**，且可以做**特征值分解 (EVD)**
$$
\boldsymbol{R}_{\v{X}} = \boldsymbol{Q} \boldsymbol{\varLambda}_{\v{X}} \boldsymbol{Q}^{\mathrm{H}}
$$
其中 $\boldsymbol{Q}$ 是酉矩阵，$\boldsymbol{\varLambda}_{\v{X}} = \text{diag}(\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n})$，$\lambda_{i} \geq 0$。取 $\boldsymbol{A} = \boldsymbol{Q}^{\mathrm{H}}$，即可保证 $\boldsymbol{R}_{\v{Y}} = \boldsymbol{\varLambda}_{\v{X}}$。

> [!theorem] 去相关变换
> 对随机变量 $\v{X}$，取 $\boldsymbol{R}_{\v{X}}$ 的**特征值分解** $\boldsymbol{R}_{\v{X}} = \boldsymbol{Q} \boldsymbol{\varLambda}_{\v{X}} \boldsymbol{Q}^{\mathrm{H}}$，则线性变换 
> $$\v{Y} = \boldsymbol{Q}^{\mathrm{H}} \v{X}$$ 
> 各分量**不相关**，且 $\boldsymbol{R}_{\v{Y}} = \boldsymbol{\varLambda}_{\v{X}}$，这个过程称为**去相关 (decorrelation)** 或**白化 (whitening)**。

### 主成分分析 (PCA)

考虑 $\v{X}$ 沿某个方向 $\v{\alpha}$ 的**投影**
$$
\mathrm{proj}_{\v{\alpha}} \v{X} = \v{\alpha} \left( \v{\alpha}^{\mathrm{T}} \v{\alpha} \right)^{-1} \v{\alpha}^{\mathrm{T}} \v{X} 
$$
我们希望找到 $\v{\alpha}$ 使得这个投影「最大」，即
$$
\vu{\alpha} = \arg\limits_{\v{\alpha}} \max\limits_{\|\v{\alpha}\| = 1} \mathbb{E}\left[ \left\| \mathrm{proj}_{\v{\alpha}} \v{X} \right\|^{2} \right]
= \arg\limits_{\v{\alpha}} \max\limits_{\|\v{\alpha}\| = 1} \mathbb{E}\left[ \dfrac{\left( \v{\alpha}^{\mathrm{T}} \v{X} \right)^{2}}{\v{\alpha}^{\mathrm{T}} \v{\alpha}} \right]
= \arg\limits_{\v{\alpha}} \max\limits_{\|\v{\alpha}\| = 1} \v{\alpha}^{\mathrm{T}} \boldsymbol{R}_{\v{X}} \v{\alpha}
$$

引入 Lagrange 乘子 $\lambda$，构造 Lagrange 函数 
$$
\mathcal{L}(\v{\alpha}, \lambda) = \v{\alpha}^{\mathrm{T}} \boldsymbol{R}_{\v{X}} \v{\alpha} - \lambda (\v{\alpha}^{\mathrm{T}} \v{\alpha} - 1)
$$
对 $\v{\alpha}$ 求梯度并令其为零，有
$$
\nabla_{\v{\alpha}} \mathcal{L}(\v{\alpha}, \lambda) = 2 \boldsymbol{R}_{\v{X}} \v{\alpha} - 2 \lambda \v{\alpha} = 0 \quad \Longrightarrow \quad \boldsymbol{R}_{\v{X}} \v{\alpha} = \lambda \v{\alpha}
$$
因此，$\v{\alpha}$ 必须是 $\boldsymbol{R}_{\v{X}}$ 的**特征向量 (eigenvector)**，$\lambda$ 是对应的**特征值 (eigenvalue)**。而
$$
\v{\alpha}^{\mathrm{T}} \boldsymbol{R}_{\v{X}} \v{\alpha} = \lambda \v{\alpha}^{\mathrm{T}} \v{\alpha} = \lambda
$$
因此应取最大的特征值对应的特征向量。

### 双正交展开 (bi-orthogonal expansion)

#### 随机变量列的双正交展开

在[[#去相关 (decorrelation)]] 中，我们已经知道可以通过线性变换将随机变量列 $\v{X}$ 变为不相关的随机变量列 $\v{Y} = \boldsymbol{Q}^{\mathrm{H}} \v{X}$，其中 $\boldsymbol{Q}$ 是 $\boldsymbol{R}_{\v{X}}$ 的特征向量矩阵。

考虑逆变换
$$
\v{X} = \boldsymbol{Q} \v{Y} = \sum\limits_{i=1}^{n} Y_{i} \v{q}_{i}
$$
其中 $\v{q}_{i}$ 是 $\boldsymbol{Q}$ 的第 $i$ 列，即 $\boldsymbol{R}_{\v{X}}$ 的第 $i$ 个特征向量。显然，

+ $\left< Y_{i}, Y_{j} \right> = \mathbb{E}[Y_{i} Y_{j}^{*}] = 0$，$\forall i \neq j$，即 $\v{Y}$ 的各分量**正交**；
+ $\left< \v{q}_{i}, \v{q}_{j} \right> = \v{q}_{i}^{\mathrm{H}} \v{q}_{j} = 0$，$\forall i \neq j$，即 $\boldsymbol{Q}$ 的各列**正交**。

因此，上面的展开称为**双正交展开 (bi-orthogonal expansion)**。

#### 随机过程的双正交展开

考虑宽平稳随机过程 $X(t)$，我们希望找到一组函数 $\{\phi_{n}(t)\}$ 和一组随机变量 $\{\alpha_{n}\}$，使得
$$
X(t) = \sum\limits_{k=-\infty}^{+\infty} \alpha_{k} \phi_{k}(t)
$$
且 $\{\phi_{n}(t)\}$ 和 $\{\alpha_{n}\}$ 分别**正交**，即
$$
\begin{cases}
\left< \phi_{i}, \phi_{j} \right> = \dint_{-\infty}^{+\infty} \phi_{i}(t) \phi_{j}^{*}(t) \dif t = \delta_{ij}, \\
\left< \alpha_{i}, \alpha_{j} \right> = \mathbb{E}[\alpha_{i} \alpha_{j}^{*}] = \lambda_{i} \delta_{ij}
\end{cases}
$$
其中 $\lambda_{i} \geq 0$。

注意到 $\boldsymbol{R}_{\v{X}}$ 的特征向量 $\left\{  \v{q}_{i}  \right\}$ 是**正交归一化**的，因此可取 $\phi_{i}(t) = q_{i}(t)$，其中 $q_{i}(t)$ 是 $\v{q}_{i}$ 的插值函数，即有
$$
\boldsymbol{R}_{\v{X}} \v{q}_{i} = \left( \sum\limits_{j=1}^{n} R_{X} (k, j) \phi_{i}(j) \right)_{k} = \lambda_{i} \v{q}_{i} = \big( \lambda_{i}\phi_{i}(k) \big) _{k}
$$
取 $n \to \infty$，则可以猜想有
$$
\dint_{-\infty}^{+\infty} R_{X}(t,s) \phi_{i}(s) \dif s = \lambda_{i} \phi_{i}(t)
$$


