## 随机变量的统计特性

### 随机变量的分布

离散随机变量 $X$ 可用其**概率质量函数 (probability mass function, PMF)** $P_{X}(x) = P \left\{ X = x \right\}$ 描述；连续随机变量 $X$ 可用其**累积分布函数 (cumulative distribution function, CDF)** $F_{X}(x) = P \left\{X \leq x\right\}$ 或**概率密度函数 (probability density function, PDF)** $f_{X}(x) = \cfrac{\dif F_{X}(x)}{\dif x}$ 描述。

**条件于 $Y$ 的随机变量 $X$** 表示为 $X \mid Y$，其 PMF 或 PDF、CDF 分别为
$$
\begin{align} 
&P_{X \mid Y}(x \mid y) = P \left\{ X = x \mid Y = y \right\} = \dfrac{P_{X,Y}(x,y)}{P_{Y}(y)}, \\
&f_{X \mid Y}(x \mid y) = \dfrac{f_{X,Y}(x,y)}{f_{Y}(y)}, \quad F_{X \mid Y}(x \mid y) = \dint_{-\infty}^{x} f_{X \mid Y}(t \mid y) \dif t
\end{align}
$$
有**全概率公式 (law of total probability)**
$$
\begin{align}
&P_{X}(x) = \sum\limits_{y} P_{X \mid Y}(x \mid y) P_{Y}(y), \\
&F_{X}(x) = \dint_{-\infty}^{+\infty} F_{X \mid Y}(x \mid y) f_{Y}(y) \dif y, \quad
f_{X}(x) = \dint_{-\infty}^{+\infty} f_{X \mid Y}(x \mid y) f_{Y}(y) \dif y
\end{align}
$$

### 随机变量的数字特征

使用以下数字特征来描述随机变量的统计特性：
+ **均值 (mean)** 或**期望 (expectation)** $\mathbb{E} \left[ X \right] = \dint_{-\infty}^{+\infty} x f_{X}(x) \dif x$（对离散随机变量为 $\mathbb{E} \left[ X \right] = \sum\limits_{x} x P_{X}(x)$），描述随机变量的中心位置；
+ **方差 (variance)** $\mathrm{Var}[X] = \mathbb{E} \left[ |X - \mathbb{E}[X]|^{2} \right]$，描述随机变量的离散程度。

方程和均值的关系为
$$
\mathrm{Var}[X] = \mathbb{E}\left[|X|^{2}\right] - |\mathbb{E}[X]|^{2}
$$

对**条件于 $Y$ 的随机变量 $X$**，类似定义：
+ **条件均值 (conditional mean)** $\mathbb{E}[X|Y] = \dint_{-\infty}^{+\infty} x f_{X|Y}(x|y) \dif x$（对离散随机变量为 $\mathbb{E}[X|Y] = \sum\limits_{x} x P_{X|Y}(x|y)$），满足**重期望公式 (law of total expectation)** 
$$\mathbb{E}[X] = \mathbb{E}_{Y} \big[\mathbb{E}_{X}[X|Y]\big]$$
+ **条件方差 (conditional variance)** $\mathrm{Var}[X|Y] = \mathbb{E} \left[ \left| X - \mathbb{E}[X|Y] \right|^{2} \Big| Y \right]$，满足**全方差公式 (law of total variance)** 
$$\mathrm{Var}[X] = \mathrm{Var} \big[ \mathbb{E}[X|Y] \big] + \mathbb{E} \big[ \mathrm{Var}[X|Y] \big]$$

### 随机变量的特征函数

类似于 Fourier 变换，随机变量也有其对应的**特征函数 (characteristic function)**，它描述了随机变量在「某种意义的」频域上的分布情况。

> [!definition] 特征函数
> 随机变量 $X$ 的**特征函数 (characteristic function)** 定义为
> $$
> \phi_{X}(\omega) = \mathbb{E} \left[ \e^{\J \omega X} \right] = \dint_{-\infty}^{+\infty} \e^{\J \omega x} f_{X}(x) \dif x
> $$
^TezhengHanshu

需要注意，
+ 上述特征函数的积分中的**指数函数为 $\e^{\J \omega x}$**，而常见的 Fourier 变换中的指数函数通常为 $\e^{-\J \omega t}$；
+ 特征函数不同于一般信号的 Fourier 变换，其积分变量是随机变量 $X$ 的取值 $x$ 而非时间 $t$，所刻画的是 **$X$ 的分布（随机性）的「频」域特性**。

如果 $X$ 为离散随机变量，类比于 DTFT 与 $z$ 变换的关系，随机变量也有**母函数 (moment generating function, MGF)**。同样，不同于常见的 $z$ 变换表述，此处求和中使用的指数函数为 $z^{x}$ 而非 $z^{-x}$。

> [!definition] 母函数
> 离散随机变量 $X$ 的**母函数 (moment generating function, MGF)** 定义为
> $$
> G_{X}(z) = \mathbb{E} \left[ z^{X} \right] = \sum\limits_{x} z^{x} P_{X}(x)
> $$
> $X$ 的**特征函数**可以表示为
> $$
> \phi_{X}(\omega) = G_{X}(\e^{\J \omega})
> $$
^MuHanshu

特别地，$X \in \mathbb{Z}$ 时，母函数成为幂级数或 Laurent 级数的形式。

### 随机变量的相互关系

#### 随机变量的独立

两个随机变量 $X$ 和 $Y$ 相互**独立 (independent)**，如果对于任意 $x$ 和 $y$，都有
$$
f_{X,Y}(x,y) = f_{X}(x) f_{Y}(y)
\quad \text{或} \quad
P_{X,Y}(x,y) = P_{X}(x) P_{Y}(y)
$$
即，$X$ 的取值不影响 $Y$ 的取值，反之亦然。

#### 随机变量的相关

**相关**描述两个随机变量之间的线性关系，即寻找 $Y \simeq \alpha X$ 的关系。为此，考虑**均方误差 (MSE)**：
$$
\text{MSE} = \mathbb{E}[(Y - \alpha X)^2]
$$
我们希望寻找 $\arg \min\limits_{\alpha} \text{MSE}$，因此令
$$
\frac{\partial \text{MSE}}{\partial \alpha} = \dfrac{\partial}{\partial \alpha} \mathbb{E}[(Y - \alpha X)^2] = 0
$$
直接**交换求导与求期望**两个微积分过程，得到
$$
\mathbb{E}[-2X(Y - \alpha X)] = 0 \quad \Longrightarrow \quad \alpha = \frac{\mathbb{E}[XY]}{\mathbb{E}[X^2]}
$$

> [!definition] 相关
> 两个随机变量 $X$ 和 $Y$ 之积的期望 $\mathbb{E}[XY]$ 即称为二者的**相关** (correlation)。
^SuijiBianliangXiangguan

相关具有**双线性 (bilinear)** 性质，即对于任意常数 $a$、$b$，有
$$
\begin{cases}
\mathbb{E}[(aX_{1} + bX_{2})Y] = a\mathbb{E}[X_{1}Y] + b\mathbb{E}[X_{2}Y], \\
\mathbb{E}[X(aY_{1} + bY_{2})] = a\mathbb{E}[XY_{1}] + b\mathbb{E}[XY_{2}]
\end{cases}
$$

> [!definition] 协方差
> 两个随机变量 $X$ 和 $Y$ 的**协方差 (covariance)** 定义为
> $$
> \text{Cov}(X,Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]
> $$

显然，协方差也具有**双线性**性质，并且 $\text{Cov}(X,X) = \text{Var}(X)$。

> [!danger] 独立性与相关性的区别
>
> 两个随机变量 $X$ 和 $Y$ **独立**，意味着 
> $$
> f_{X,Y}(x,y) = f_{X}(x)f_{Y}(y)
> \quad \text{或} \quad
> P_{X,Y}(x,y) = P_{X}(x) P_{Y}(y)
> $$
> 而**相关**只描述两个随机变量之间的线性关系，两个随机变量 $X$ 和 $Y$ **不相关**，仅代表 
> $$
> \mathrm{Cov}\left[ X,Y \right] = 0
> \quad \text{i.e.} \quad
> \mathbb{E}[XY] = \mathbb{E}[X]\mathbb{E}[Y]
> $$
> 显然，**独立性蕴含不相关性**，但反之不然。

> [!note] 相关性的几何描述
> 考虑随机变量 $X$ 和 $Y$ 的**内积空间**，定义**内积**为
> $$
> \langle X, Y \rangle = \mathbb{E}[XY]
> $$
> 则**范数**即为
> $$
> \|X\| = \sqrt{\langle X, X \rangle} = \sqrt{\mathbb{E}[X^2]}
> $$
> 这样，$Y$ 在 $X$ 方向上的**投影**为
> $$
> \text{proj}_{X}Y = \frac{\langle X, Y \rangle}{\|X\|^2} X = \frac{\mathbb{E}[XY]}{\mathbb{E}[X^2]} X
> $$
> 与前面通过最小化 MSE 得到的结果一致。
> 
> 进一步地，考虑多个随机变量 $X_{1}, X_{2}, \ldots, X_{n}$，记 $Y$ 在这些变量张成的子空间上的投影为
> $$
> \text{proj}_{X_{1}, X_{2}, \ldots, X_{n}} Y = \alpha_{1} X_{1} + \alpha_{2} X_{2} + \cdots + \alpha_{n} X_{n} = \sum\limits_{i=1}^{n} \alpha_{i} X_{i} = \v{\alpha}^{\mathrm{T}} \v{X}
> $$
> 于是 $\v{\alpha} = \arg\min\limits_{\vu{\alpha}} \mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X}) \big]$，而
> $$
> \begin{align}
> \mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X})^2 \big] 
> &= \mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X})^{\mathrm{T}}(Y-\vu{\alpha}^{\mathrm{T}}\v{X}) \big] \\
> &= \mathbb{E} \big[(Y-\v{X}^{\mathrm{T}}\vu{\alpha})^{\mathrm{T}}(Y-\v{X}^{\mathrm{T}}\vu{\alpha}) \big] \\
> &= \mathbb{E}[Y^2] - \mathbb{E} [Y^{\mathrm{T}} \v{X}^{\mathrm{T}}] \vu{\alpha} - \vu{\alpha}^{\mathrm{T}} \mathbb{E}[\v{X} Y] + \vu{\alpha}^{\mathrm{T}} \mathbb{E}[\v{X} \v{X}^{\mathrm{T}}] \vu{\alpha}
> \end{align}
> $$
> 对 $\vu{\alpha}$ 求梯度并令其为零，即
> $$
> \nabla_{\vu{\alpha}} \mathbb{E} \big[(Y-\vu{\alpha}^{\mathrm{T}}\v{X})^2 \big] \Big|_{\vu{\alpha} = \v{\alpha}} = -\mathbb{E}[\v{X} Y] - \mathbb{E}[\v{X} Y] + 2 \mathbb{E}[\v{X} \v{X}^{\mathrm{T}}] \v{\alpha} = 0
> $$
> 故
> $$
> \v{\alpha} = \big(\mathbb{E}[\v{X} \v{X}^{\mathrm{T}}]\big)^{-1} \mathbb{E}[\v{X} Y]
> $$
> 即，**$Y$ 与 $\v{X}$ 各元素的相关对应着其在 $\v{X}$ 张成的子空间上的投影系数**。

## 常见分布及其性质

### Gauss 分布

称随机变量 $X$ 服从 **Gauss 分布 (Gaussian distribution)**，如果其概率密度函数为
$$
f_{X}(x) = \dfrac{1}{\sqrt{2\pi} \sigma} \exp\left( -\dfrac{(x - \mu)^{2}}{2\sigma^{2}} \right)
$$
记为 $X \sim \mathscr{N}(\mu, \sigma^{2})$，其中 $\mu \in \mathbb{R}$，$\sigma^{2} > 0$。

若 $X \sim \mathscr{N}(\mu, \sigma^{2})$，则
+ $|X|$ 的均值为
$$
\begin{align} 
\mathbb{E} \left[ |X| \right] &= \dint_{-\infty}^{\infty} |x| f_{X}(x) \dif x = \dfrac{1}{\sqrt{2\pi} \sigma} \left( \dint_{-\infty}^{0} -x \e^{ -\tfrac{(x - \mu)^{2}}{2\sigma^{2}} } \dif x + \dint_{0}^{\infty} x \e^{ -\tfrac{(x - \mu)^{2}}{2\sigma^{2}} } \dif x \right) \\
&= \mu \left( 1 - 2\varPhi\left( -\dfrac{\mu}{\sigma} \right) \right) + \dfrac{2\sigma}{\sqrt{2\pi}} \exp\left( -\dfrac{\mu^{2}}{2\sigma^{2}} \right)
\end{align}
$$
其中 $\varPhi(x)$ 是标准 Gauss 分布的分布函数。特别地，当 $\mu = 0$ 时，有
$$
\mathbb{E} \left[ |X| \right] = \dfrac{2\sigma}{\sqrt{2\pi}}
$$
亦即，$|X - \mu|$ 或**偏离半径**的均值为
$$
\mathbb{E} \left[ |X - \mu| \right] = \dfrac{2\sigma}{\sqrt{2\pi}}
$$

Gauss 分布的**特征函数 (characteristic function)** 为
$$
\phi_{X}(\omega) = \mathbb{E} \left[ \exp(\J \omega X) \right] = \exp\left( \J \mu \omega - \dfrac{\sigma^{2} \omega^{2}}{2} \right)
$$

## 多元相关的矩阵分析

对于一组随机变量 $\v{X} = \begin{pmatrix}X_{1} & X_{2} & \cdots & X_{n}\end{pmatrix}^{\mathrm{T}}$，其**相关矩阵 (correlation matrix)** 定义为
$$
\boldsymbol{R}_{\v{X}} = \mathbb{E} \left[\v{X} \v{X}^{\mathrm{H}}\right] = \begin{pmatrix}
\mathbb{E}[X_{1} X_{1}^{*}] & \mathbb{E}[X_{1} X_{2}^{*}] & \cdots & \mathbb{E}[X_{1} X_{n}^{*}] \\
\mathbb{E}[X_{2} X_{1}^{*}] & \mathbb{E}[X_{2} X_{2}^{*}] & \cdots & \mathbb{E}[X_{2} X_{n}^{*}] \\
\vdots & \vdots & \ddots & \vdots \\
\mathbb{E}[X_{n} X_{1}^{*}] & \mathbb{E}[X_{n} X_{2}^{*}] & \cdots & \mathbb{E}[X_{n} X_{n}^{*}]
\end{pmatrix} = \big( \mathbb{E}\left[ X_{i} X_{j} \right] \big)_{i,j} 
$$
显然，相关矩阵是**共轭对称**的，并且是**正定**的。

若将 $\v{X}$ 的元素下标 $n$ 视作时间，则 $\v{X}$ 可视作随机过程 $X(n)$ 的一个**样本向量 (sample vector)**，其相关矩阵为该随机过程在这些时刻的相关函数值，即
$$
\boldsymbol{R}_{\v{X}} = \big( R_{X}(i,j) \big)_{i,j}
$$

### 去相关 (decorrelation)

考虑线性变换 $\v{Y} = \boldsymbol{A} \v{X}$，其中 $\boldsymbol{A}$ 为方阵。我们希望找到  使得 $\v{Y}$ 的各分量**不相关**，即 $\mathbb{E}[Y_{i} Y_{j}^{*}] = 0$，$\forall i \neq j$，或
$$
\boldsymbol{R}_{\v{Y}} = \mathbb{E}\left[ \v{Y}\v{Y}^{\mathrm{H}} \right] = \mathbb{E}\left[ \boldsymbol{A} \v{X}\v{X}^{\mathrm{H}} \boldsymbol{A}^{\mathrm{H}} \right] = \boldsymbol{A} \boldsymbol{R}_{\v{X}} \boldsymbol{A}^{\mathrm{H}}
= \boldsymbol{\varLambda}_{\v{Y}}
$$
其中 $\boldsymbol{\varLambda}_{\v{Y}}$ 是对角阵。

因 $\boldsymbol{R}_{\v{X}}$ 是正定的，故其**特征值均非负**，且可以做**特征值分解 (EVD)**
$$
\boldsymbol{R}_{\v{X}} = \boldsymbol{Q} \boldsymbol{\varLambda}_{\v{X}} \boldsymbol{Q}^{\mathrm{H}}
$$
其中 $\boldsymbol{Q}$ 是酉矩阵，$\boldsymbol{\varLambda}_{\v{X}} = \text{diag}(\lambda_{1}, \lambda_{2}, \ldots, \lambda_{n})$，$\lambda_{i} \geq 0$。取 $\boldsymbol{A} = \boldsymbol{Q}^{\mathrm{H}}$，即可保证 $\boldsymbol{R}_{\v{Y}} = \boldsymbol{\varLambda}_{\v{X}}$。

> [!theorem] 去相关变换
> 对随机变量 $\v{X}$，取 $\boldsymbol{R}_{\v{X}}$ 的**特征值分解** $\boldsymbol{R}_{\v{X}} = \boldsymbol{Q} \boldsymbol{\varLambda}_{\v{X}} \boldsymbol{Q}^{\mathrm{H}}$，则线性变换 
> $$\v{Y} = \boldsymbol{Q}^{\mathrm{H}} \v{X}$$ 
> 各分量**不相关**，且 $\boldsymbol{R}_{\v{Y}} = \boldsymbol{\varLambda}_{\v{X}}$，这个过程称为**去相关 (decorrelation)** 或**白化 (whitening)**。

### 主成分分析 (PCA)

考虑 $\v{X}$ 沿某个方向 $\v{\alpha}$ 的**投影**
$$
\mathrm{proj}_{\v{\alpha}} \v{X} = \v{\alpha} \left( \v{\alpha}^{\mathrm{T}} \v{\alpha} \right)^{-1} \v{\alpha}^{\mathrm{T}} \v{X} 
$$
我们希望找到 $\v{\alpha}$ 使得这个投影「最大」，即
$$
\vu{\alpha} = \arg\limits_{\v{\alpha}} \max\limits_{\|\v{\alpha}\| = 1} \mathbb{E}\left[ \left\| \mathrm{proj}_{\v{\alpha}} \v{X} \right\|^{2} \right]
= \arg\limits_{\v{\alpha}} \max\limits_{\|\v{\alpha}\| = 1} \mathbb{E}\left[ \dfrac{\left( \v{\alpha}^{\mathrm{T}} \v{X} \right)^{2}}{\v{\alpha}^{\mathrm{T}} \v{\alpha}} \right]
= \arg\limits_{\v{\alpha}} \max\limits_{\|\v{\alpha}\| = 1} \v{\alpha}^{\mathrm{T}} \boldsymbol{R}_{\v{X}} \v{\alpha}
$$

引入 Lagrange 乘子 $\lambda$，构造 Lagrange 函数 
$$
\mathcal{L}(\v{\alpha}, \lambda) = \v{\alpha}^{\mathrm{T}} \boldsymbol{R}_{\v{X}} \v{\alpha} - \lambda (\v{\alpha}^{\mathrm{T}} \v{\alpha} - 1)
$$
对 $\v{\alpha}$ 求梯度并令其为零，有
$$
\nabla_{\v{\alpha}} \mathcal{L}(\v{\alpha}, \lambda) = 2 \boldsymbol{R}_{\v{X}} \v{\alpha} - 2 \lambda \v{\alpha} = 0 \quad \Longrightarrow \quad \boldsymbol{R}_{\v{X}} \v{\alpha} = \lambda \v{\alpha}
$$
因此，$\v{\alpha}$ 必须是 $\boldsymbol{R}_{\v{X}}$ 的**特征向量 (eigenvector)**，$\lambda$ 是对应的**特征值 (eigenvalue)**。而
$$
\v{\alpha}^{\mathrm{T}} \boldsymbol{R}_{\v{X}} \v{\alpha} = \lambda \v{\alpha}^{\mathrm{T}} \v{\alpha} = \lambda
$$
因此应取最大的特征值对应的特征向量。

### 双正交展开 (bi-orthogonal expansion)

#### 随机变量列的双正交展开

在[[#去相关 (decorrelation)]] 中，我们已经知道可以通过线性变换将随机变量列 $\v{X}$ 变为不相关的随机变量列 $\v{Y} = \boldsymbol{Q}^{\mathrm{H}} \v{X}$，其中 $\boldsymbol{Q}$ 是 $\boldsymbol{R}_{\v{X}}$ 的特征向量矩阵。

考虑逆变换
$$
\v{X} = \boldsymbol{Q} \v{Y} = \sum\limits_{i=1}^{n} Y_{i} \v{q}_{i}
$$
其中 $\v{q}_{i}$ 是 $\boldsymbol{Q}$ 的第 $i$ 列，即 $\boldsymbol{R}_{\v{X}}$ 的第 $i$ 个特征向量。显然，

+ $\left< Y_{i}, Y_{j} \right> = \mathbb{E}[Y_{i} Y_{j}^{*}] = 0$，$\forall i \neq j$，即 $\v{Y}$ 的各分量**正交**；
+ $\left< \v{q}_{i}, \v{q}_{j} \right> = \v{q}_{i}^{\mathrm{H}} \v{q}_{j} = 0$，$\forall i \neq j$，即 $\boldsymbol{Q}$ 的各列**正交**。

因此，上面的展开称为**双正交展开 (bi-orthogonal expansion)**。

#### 随机过程的双正交展开

考虑宽平稳随机过程 $X(t)$，我们希望找到一组函数 $\{\phi_{n}(t)\}$ 和一组随机变量 $\{\alpha_{n}\}$，使得
$$
X(t) = \sum\limits_{k=-\infty}^{+\infty} \alpha_{k} \phi_{k}(t)
$$
且 $\{\phi_{n}(t)\}$ 和 $\{\alpha_{n}\}$ 分别**正交**，即
$$
\begin{cases}
\left< \phi_{i}, \phi_{j} \right> = \dint_{-\infty}^{+\infty} \phi_{i}(t) \phi_{j}^{*}(t) \dif t = \delta_{ij}, \\
\left< \alpha_{i}, \alpha_{j} \right> = \mathbb{E}[\alpha_{i} \alpha_{j}^{*}] = \lambda_{i} \delta_{ij}
\end{cases}
$$
其中 $\lambda_{i} \geq 0$。

注意到 $\boldsymbol{R}_{\v{X}}$ 的特征向量 $\left\{  \v{q}_{i}  \right\}$ 是**正交归一化**的，因此可取 $\phi_{i}(t) = q_{i}(t)$，其中 $q_{i}(t)$ 是 $\v{q}_{i}$ 的插值函数，即有
$$
\boldsymbol{R}_{\v{X}} \v{q}_{i} = \left( \sum\limits_{j=1}^{n} R_{X} (k, j) \phi_{i}(j) \right)_{k} = \lambda_{i} \v{q}_{i} = \big( \lambda_{i}\phi_{i}(k) \big) _{k}
$$
取 $n \to \infty$，则可以猜想有
$$
\dint_{-\infty}^{+\infty} R_{X}(t,s) \phi_{i}(s) \dif s = \lambda_{i} \phi_{i}(t)
$$


