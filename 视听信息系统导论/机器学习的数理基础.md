## 梯度下降

### 梯度下降优化的引入

考虑一个线性回归模型：
+ 输入 $m$ 个特征 $x_1, x_2, \cdots, x_m$，输出 $y$；
+ 模型有 $m$ 个权重系数 $w_1, w_2, \cdots, w_m$ 和一个偏置 $b$；
+ 模型的预测输出为 $\hat{y} = w_1 x_1 + w_2 x_2 + \cdots + w_m x_m + b = \v{w}^{\mathrm{T}} \v{x} + b$。

假设有 $N$ 个样本数据 $\left\{ \v{x}^{(i)}, y^{(i)} \right\}$ 组成数据集 $\left\{ \boldsymbol{X}, \v{y} \right\}$，希望通过调整模型参数 $\v{w}, b$，使得模型预测输出 $\hat{y}^{(i)}$ 尽可能接近真实输出 $y^{(i)}$。为此，可以定义**损失函数 (loss function)** 来衡量预测值与真实值之间的差距。常用的损失函数是**均方误差 (mean squared error, MSE)**：
$$
\mathscr{L}\left( \v{w}, b; \boldsymbol{X}, \v{y} \right) = \dfrac{1}{N} \sum_{i=1}^{N} \left( \hat{y}^{(i)} - y^{(i)} \right)^2 = \dfrac{1}{N} \sum_{i=1}^{N} \left( \v{w}^{\mathrm{T}} \v{x}^{(i)} + b - y^{(i)} \right)^2
$$
求解
$$
\v{w}^{*}, b^{*} = \arg\limits_{\v{w}, b}\min \mathscr{L}\left( \v{w}, b; \boldsymbol{X}, \v{y} \right)
$$
可以使用**梯度下降 (gradient descent)** 方法。

> [!algo.] 梯度下降算法
> **梯度下降算法**是一种迭代优化算法，用于寻找函数的局部最小值。
> 
> ---
> 
> **GIVEN —** 
> 初始参数 $\boldsymbol{W}$。
> 
> **REPEAT —**
> 1. 计算损失函数 $\mathscr{L}$ 关于参数 $\boldsymbol{W}$ 的梯度 $\nabla_{\boldsymbol{W}} \mathscr{L}$；
> 2. 沿梯度的反方向更新参数，$\boldsymbol{W} \Leftarrow \boldsymbol{W} - \eta \nabla_{\boldsymbol{W}} \mathscr{L}$；
> 
> 　**UNTIL —** 满足逼近最小值点的结束条件。
> 
> **OUTPUT —**
> 优化后参数 $\boldsymbol{W}$。
> 
> ---
> 
> 其中：
> + $\eta$ — **学习率 (learning rate)**，控制每次更新的步长。

### 训练、测试与验证

#### 数据集的划分

在机器学习中，通常将数据集划分为**训练集 (training set)**、**验证集 (validation set)** 和**测试集 (test set)** 三部分：
+ 训练集用于模型的训练，即通过梯度下降等方法优化模型参数；
+ 验证集用于模型的调参和选择，帮助判断模型是否过拟合或欠拟合；
+ 测试集用于评估模型的最终性能，检验模型在未见过的数据上的表现。

模型在训练数据集上得到的误差称为**训练误差 (training error)**，而在所期望的原始样本分布上得到的误差称为**泛化误差 (generalization error)**。泛化误差永远不能准确地计算出，因为「原始样本」是一个虚构的对象。在实际中，只能通过将模型应用于一个独立的测试集来估计泛化误差，该测试集由随机选取的、未曾在训练集中出现的数据样本构成。 

#### 模型的复杂度

当模型太简单时，可能无法捕捉数据中的复杂模式，导致**欠拟合 (underfitting)**；当模型过于复杂时，可能会记住训练数据中的噪声，导致**过拟合 (overfitting)**。在固定训练数据集下，模型复杂度越高，训练误差应该始终越低，参数数量等于或大于训练样本数量的模型可以将训练误差降低到零。然而，过于复杂的模型在验证集和测试集上的误差可能会增加，因为它们无法很好地泛化到未见过的数据。

**模型复杂度 (model complexity)** 直接影响训练效果与测试表现。其可以通过多种方式衡量，例如：
+ 模型参数的数量；
+ 模型迭代表达式的阶数；
+ 模型的自由度；
+ 模型的 VC 维度（Vapnik-Chervonenkis dimension）。

限制模型的阶数、参数的数量等仅是一个粗略的避免过拟合的方法，容易导致欠拟合。更常用的方法是引入**正则化 (regularization)**，在损失函数中添加一个惩罚项，以控制模型的复杂度。

> [!algo.] L2 正则化
> **L2 正则化**是一种常用的正则化方法，通过在损失函数中添加参数的平方和作为惩罚项，来控制模型的复杂度。
> 
> ---
> 
> **GIVEN —** 
> 初始参数 $\boldsymbol{W}$，训练集 $\left\{ \boldsymbol{X}, \v{y} \right\}$。
> 
> **REPEAT —**
> 1. 构建 L2 惩罚项 $R(\boldsymbol{W}) = \dfrac{1}{2} \|\boldsymbol{W}\|^2$；
> 2. 计算正则化损失函数 $\mathscr{L}_{\mathrm{reg}} = \mathscr{L} + \lambda R(\boldsymbol{W})$ 的梯度 $\nabla_{\boldsymbol{W}} \mathscr{L}_{\mathrm{reg}}$；
> 3. $\boldsymbol{W} \Leftarrow \boldsymbol{W} - \eta \nabla_{\boldsymbol{W}} \mathscr{L}_{\mathrm{reg}}$；
> 
> 　**UNTIL —** 满足逼近最小值点的结束条件。
> 
> **OUTPUT —**
> 优化后参数 $\boldsymbol{W}$。
> 
> ---
> 
> 其中：
> + $\lambda$ — 正则化强度，控制惩罚项的权重；
> + $\eta$ — 学习率。
> 

L2 正则化的梯度下降有时也称为**权重衰减 (weight decay)**，因为
$$
\begin{align}
\boldsymbol{W} \Leftarrow \boldsymbol{W} - \eta \nabla_{\boldsymbol{W}} \mathscr{L}_{\mathrm{reg}} &= \boldsymbol{W} - \eta \left( \nabla_{\boldsymbol{W}} \mathscr{L} + \lambda \nabla_{\boldsymbol{W}} \dfrac{\|\boldsymbol{W}\|^{2}}{2} \right) \\
&= \boldsymbol{W} - \eta \nabla_{\boldsymbol{W}} \mathscr{L} - \eta \lambda \boldsymbol{W} \\
&= (1 - \eta \lambda) \boldsymbol{W} - \eta \nabla_{\boldsymbol{W}} \mathscr{L}
\end{align}
$$
梯度下降同时会将已有的模型参数推向较小的值，从而减少模型的复杂度。

> [!note] 正则化器的选择
> 除了 L2 正则化器外，还有 L1 正则化器、弹性网络 (Elastic Net)、Dropout 等多种正则化方法。不同的正则化器适用于不同的问题，需要根据具体情况选择合适的正则化器。
> 
> + **L2 正则化**线性模型构成经典的岭回归 (ridge regression)算法，对较大的权重向量惩罚较大，使得学习算法偏向于**在大量特征上均匀分布权重**的模型，适用于大多数情况。
> + **L1 正则化**线性模型构成统计学中的 Lasso 回归 (Lasso regression) 算法，对较大的权重向量惩罚较大，会导致模型将权重集中在一小部分特征上，而**将其他权重清除为零**，使得学习算法偏向于稀疏权重的模型，适用于**特征选择 (feature selection)**。

## 神经网络

### 线性分类器

线性分类器 (linear classifier) 是一种简单的分类模型，其基本思想是通过一个线性函数将输入数据映射到不同的类别。

#### 二分类任务的损失函数

对于一个输入向量 $\v{x} \in \mathbb{R}^{m}$，**线性二分类**的输出可以表示为
$$
\hat{y} = g(z) = g\left( \v{w}^{\mathrm{T}} \v{x} + b \right), \qquad
g(z) = \begin{cases}
1, & z \geq 0 \\
0, & z < 0
\end{cases}
$$
其中，$\v{w} \in \mathbb{R}^{m}$ 是权重向量，$b \in \mathbb{R}$ 是偏置，$\v{w}^{\mathrm{T}} \v{x} + b = 0$ 称为**决策边界 (decision boundary)**。

对于二分类任务，直接的想法是使用 **0-1 损失函数 (0-1 loss function)**，定义为
$$
\mathscr{L}_{\text{0-1}} = \mathbb{1}_{\hat{y} \neq y} = \begin{cases}
1, & \hat{y} \neq y \\
0, & \hat{y} = y
\end{cases}
$$
对其做梯度下降，注意到
$$
\dfrac{\partial \mathscr{L}_{\text{0-1}}}{\partial w_{j}} = \dfrac{ \partial \mathscr{L}_{\text{0-1}} }{ \partial z } \dfrac{ \partial z }{ \partial w_{j} } 
$$
而 $\cfrac{ \partial \mathscr{L}_{\text{0-1}} }{ \partial z }$ **在定义域内均为 0 或 $\infty$**，难以进行梯度下降优化。

为避免阶跃导致的梯度问题，考虑到标签为 0 和 1，只要保证预测的值在 $[0,1]$ 区间即可，因此可以引入 **Logistic 函数**
$$
\sigma(z) = \dfrac{1}{1 + \e^{-z}}
$$
作为激活函数，与线性函数结合，得到对数线性模型
$$
\hat{y} = \sigma(z) = \sigma\left( \v{w}^{\mathrm{T}} \v{x} + b \right)
$$
通常称 $z = \v{w}^{\mathrm{T}} \v{x} + b$ 为 **logit**。此时若使用均方误差损失函数 $\mathscr{L_{\text{SE}}} = \left( y - \sigma\left( \v{w}^{\mathrm{T}} \v{x} + b \right) \right)^{2}$，有
$$
\begin{align} 
\dfrac{ \partial \mathscr{L}_{\text{SE}} }{ \partial w_{j} } = \dfrac{ \partial \mathscr{L}_{\text{SE}} }{ \partial \sigma(z) } \dfrac{ \partial \sigma(z) }{ \partial z } \dfrac{ \partial z }{ \partial w_{j} } &= 2 (\sigma(z) - y) \cdot (\sigma(z) - \sigma^{2}(z)) \cdot x_{j} \\
&= 2 (\sigma(z) - y) \cdot \dfrac{\e^{-z}}{(1 + \e^{-z})^{2}} \cdot x_{j}
\end{align}
$$
在**饱和区域**（即 $z$ 绝对值较大时）梯度会变得非常小，导致训练过程缓慢。

> [!definition] 交叉熵损失函数
> 可以认为分类函数是在预测标签为 1 的概率，由此引入**交叉熵损失函数 (cross-entropy loss function)**，定义为
> $$
> \begin{align} 
> \mathscr{L}_{\text{CE}} &= \begin{cases}
> - \log(\hat{y}), & y = 1, \\
> - \log(1 - \hat{y}), & y = 0,
> \end{cases}  \\
> &= - y \log(\hat{y}) - (1 - y) \log(1 - \hat{y})
> \end{align}
> $$

交叉熵损失函数的梯度为
$$
\begin{align}
\dfrac{ \partial \mathscr{L}_{\text{CE}} }{ \partial w_{j} } &= \dfrac{ \partial \mathscr{L}_{\text{CE}} }{ \partial \sigma(z) } \dfrac{ \partial \sigma(z) }{ \partial z } \dfrac{ \partial z }{ \partial w_{j} } \\
&= \left( - \dfrac{y}{\sigma(z)} + \dfrac{1 - y}{1 - \sigma(z)} \right) \cdot (\sigma(z) - \sigma^{2}(z)) \cdot x_{j}
\end{align}
$$

#### 多分类任务的损失函数




## 高级梯度优化算法

几乎所有在深度学习中出现的优化问题都是**非凸**的，因此梯度下降法在实际应用中会遇到一些挑战：
+ **局部最优**：非凸优化问题可能存在多个局部最优解，梯度下降法可能会陷入某个局部最优解而无法找到全局最优解。
+ **鞍点**：梯度为 0 的非极值点，可能导致梯度下降法停滞。
+ **梯度消失和梯度爆炸**：深层神经网络中，梯度可能变得非常小（消失）或非常大（爆炸），影响训练效果。

针对这些挑战，提出了多种改进的梯度优化算法，以下介绍几种常用的方法。

### 随机梯度下降 (SGD)

**随机梯度下降 (stochastic gradient descent, SGD)** 是对梯度下降法的改进。它在每次迭代中仅使用一个样本（或一小批样本）来计算梯度，从而减少计算量并引入随机性，有助于跳出局部最优。

> [!algo.] 随机梯度下降
> **随机梯度下降 (SGD)** 是一种迭代优化算法，其基本思想是使用随机的小批量样本来近似梯度，从而加快计算速度并引入随机性。
> 
> ---
> 
> **GIVEN —** 
> 初始参数 $\boldsymbol{W}$，数据集 $\left\{ \boldsymbol{X}, \v{y} \right\}$。
> 
> **REPEAT —**
> 1. 随机抽取一个小批量样本 $\left\{ \boldsymbol{X}_{\mathrm{batch}}, \v{y}_{\mathrm{batch}} \right\}$；
> 2. 计算小批量样本的损失函数 $L_{\mathrm{batch}}$；
> 3. 计算损失函数关于参数的梯度 $\nabla_{\boldsymbol{W}} L_{\mathrm{batch}}$；
> 4. $\boldsymbol{W} \Leftarrow \boldsymbol{W} - \eta \nabla_{\boldsymbol{W}} L_{\mathrm{batch}}$；
> 
> 　**UNTIL —** 满足逼近最小值点的结束条件。
> 
> **OUTPUT —**
> 优化后参数 $\boldsymbol{W}$。
> 
> ---
> 
> 其中：
> + $\eta$ — 学习率。
> 

由于 $\mathbb{E} \left[ \nabla L\left( \boldsymbol{W};\boldsymbol{X}_{\mathrm{batch}},\v{y}_{\mathrm{batch}} \right) \right] = \nabla L\left( \boldsymbol{W}; \boldsymbol{X}, \v{y} \right)$，可认为 SGD 是对梯度下降法的一种近似。
