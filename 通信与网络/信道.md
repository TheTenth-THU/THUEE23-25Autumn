## 离散幅值信道

### 离散无记忆信道模型

**离散无记忆信道 (Discrete Memoryless Channel, DMC) 模型**假设信道在每次传输时的行为独立且不依赖于之前的传输结果。DMC 由一个条件概率来描述，即**给定信源输入符号 $X = x_{i}$ 时信宿输出符号 $Y = y_{j}$ 的概率分布 $p_{j \mid i}$**。

当给定 $X$ 的分布 $p_{i}$ 时，可以得到联合分布
$$
p_{ij} = \mathrm{Pr}\{ X = x_{i}, Y = y_{j} \} = \mathrm{Pr}\{ Y = y_{j} \mid X = x_{i} \} \mathrm{Pr}\{ X = x_{i} \} = p_{i} p_{j \mid i}
$$
信宿输出 $Y$ 的边缘分布为
$$
p_{j} = \mathrm{Pr}\{ Y = y_{j} \} = \sum\limits_{i} p_{ij} = \sum\limits_{i} p_{i} p_{j \mid i}
$$
这样，**互信息 $I(X;Y)$ 就可以给定**为
$$
\begin{align}
I(X; Y) &= H(X) + H(Y) - H(X, Y) \\
&= - \sum\limits_{i} p_{i} \log p_{i} - \sum\limits_{j} p_{j} \log p_{j} + \sum\limits_{i} \sum\limits_{j} p_{ij} \log p_{ij} \\
&= - \sum\limits_{i} \sum\limits_{j} p_{ij} \log p_{i} - \sum\limits_{i} \sum\limits_{j} p_{ij} \log p_{j} + \sum\limits_{i} \sum\limits_{j} p_{ij} \log p_{ij} \\
&= \sum\limits_{i} \sum\limits_{j} p_{ij} \log \dfrac{p_{ij}}{p_{i} p_{j}} 
= \sum\limits_{i} \sum\limits_{j} p_{ij} \log \dfrac{p_{j \mid i}}{p_{j}} 
= \mark{ \sum\limits_{i} \sum\limits_{j} p_{i} p_{j \mid i} \log \dfrac{p_{j \mid i}}{\sum\limits_{i} p_{i} p_{j \mid i}}  }
\end{align}
$$

若允许通过映射**调整输入分布 $p_{i}$**，则可以在此意义下**最大化互信息 $I(X;Y)$**，这一最大值称为**信道容量 (channel capacity)**，记为 
$$
C = \max\limits_{p_{i}} I(X; Y)
= \max\limits_{p_{i}} \sum\limits_{i} \sum\limits_{j} p_{i} p_{j \mid i} \log \dfrac{p_{j \mid i}}{\sum\limits_{i} p_{i} p_{j \mid i}}
$$
这一优化问题还有两个约束条件，即概率归一化条件 $\sum\limits_{i} p_{i} = 1$ 和非负性条件 $p_{i} \geq 0$。这是一个**非凸**的带约束优化问题，有一定的求解难度。一般 DMC 的容量需要通过数值方法求解，如 Blahut-Arimoto 算法。

### 对称二进制信道 (BSC)

我们希望得到容量的解析闭式解，因此需要在**数字通信**背景下简化 DMC 模型。

> [!definition] 对称二进制信道
> **对称二进制信道 (Binary Symmetric Channel, BSC)** 是这样的 DMC：
> + 输入和输出符号均为二进制（0 和 1），
> + 每个比特在传输过程中都有一个固定的**差错概率 (cross-over probability)** $\epsilon$，即输出比特有 $\epsilon$ 的概率变为输入比特的反码。

BSC 可以等效为
$$
Y = X \oplus Z, \quad Z \sim \mathrm{Bernoulli}(\epsilon) = \begin{pmatrix}
0 & 1 \\ 1 - \epsilon & \epsilon
\end{pmatrix}
$$
其中 $Z$ 是与输入 $X$ 独立的噪声变量，$\oplus$ 表示**按位异或**运算。

使用这一等效，BSC 的容量为
$$
\begin{align}
C &= \max\limits_{p_{i}} I(X; Y) = \max\limits_{p_{i}} I(X; X \oplus Z) \\
&= \max\limits_{p_{i}} \big( H(X \oplus Z) - H(X \oplus Z \mid X) \big) \\
&= \max\limits_{p_{i}} \big( H(X \oplus Z) - H(Z) \big) \\
&= \max\limits_{p_{i}} H(X \oplus Z) + \underbrace{ \epsilon \log \epsilon + (1 - \epsilon) \log (1 - \epsilon) }_{ \text{const} } 
\end{align}
$$
因此，最大化互信息等价于**最大化 $H(X \oplus Z)$**。由于 $X \oplus Z \in \{ 0, 1 \}$，其熵的最大值为 1，**比特均匀分布**时取得，即
$$
\begin{align}
C = 1 + \epsilon \log \epsilon + (1 - \epsilon) \log (1 - \epsilon) 
\quad\text{iff}\quad &Y \sim \mathrm{Bernoulli}(0.5) \\
&\iff X \sim \mathrm{Bernoulli}(0.5)
\end{align}
$$

### 更多离散信道模型

#### 擦除信道

**二进制擦除信道 (Binary Erasure Channel, BEC)** 是另一种常见的离散信道模型。与 BSC 不同，BEC 在传输过程中不会将比特翻转为反码，而是有一定概率 $\epsilon$ **将比特「擦除」**，即**输出一个特殊符号 $e$**，表示该比特丢失。

在 BEC 中，已知输出 $Y$ 为 0 或 1 时，可以确定输入 $X$ 的值，**没有任何不确定性**；而当输出 $Y$ 为 $e$ 时，输入 $X$ **等概地**可能是 0 或 1，存在不确定性 $H(X\mid Y=e) = 1$。这样，BEC 的容量为
$$
\begin{align}
C &= \max\limits_{p_{i}} I(X; Y) = \max\limits_{p_{i}} \big( H(X) - H(X \mid Y) \big) \\
&= \max\limits_{p_{i}} \big( H(X) - \epsilon H(X \mid Y = e) \big) \\
&= \max\limits_{p_{i}} \big( H(X) - \epsilon \cdot 1 \big) = 1 - \epsilon
\end{align}
$$
当输入比特均匀分布时取得，即 $X \sim \mathrm{Bernoulli}(0.5)$。

推广到**多进制擦除信道 (M-ary Erasure Channel, MEC)**，输入输出符号集均为 $M$ 个符号 $\{ x_{1}, x_{2}, \ldots, x_{M} \}$，每个符号在传输过程中有概率 $\epsilon$ 被**擦除**为特殊符号 $e$，不变的概率为 $1 - \epsilon$。MEC 的容量为
$$
C = \log M - \epsilon \log M = (1 - \epsilon) \log M
$$
当输入符号均匀分布时取得，此时 $p_{i} \equiv \cfrac{1}{M}$。

#### 多进制对称信道

将 BSC 推广到多进制符号集，可以得到**多进制对称信道 (M-ary Symmetric Channel, MSC)**。MSC 的输入输出符号集均为 $M$ 个符号 $\{ x_{1}, x_{2}, \ldots, x_{M} \}$，每个符号在传输过程中有概率 $\epsilon$ 被**均匀地**翻转为其他 $M-1$ 个符号中的任意一个，不变的概率为 $1 - (M-1)\epsilon$。

对 MSC，有
$$
\begin{align}
I(X; Y) &= H(Y) - H(Y \mid X) = - \sum\limits_{j=1}^{M} p_{j} \log p_{j} + \sum\limits_{i=1}^{M} p_{i} \sum\limits_{j=1}^{M} p_{j \mid i} \log p_{j \mid i} \\
&= - \sum\limits_{j=1}^{M} p_{j} \log p_{j} + \sum\limits_{i=1}^{M} p_{i} \big( (1 - (M-1)\epsilon) \log (1 - (M-1)\epsilon)  \\[-1em]
&\hspace{11.5em} + (M-1) \epsilon \log \epsilon \big) \\
&= - \sum\limits_{j=1}^{M} p_{j} \log p_{j} + \underbrace{ (1 - (M-1)\epsilon) \log (1 - (M-1)\epsilon) + (M-1) \epsilon \log \epsilon }_{ \text{const} } \\
&\le \log M + \text{const}
\end{align}
$$
因此，MSC 的容量为
$$
C = \log M + (1 - (M-1)\epsilon) \log (1 - (M-1)\epsilon) + (M-1) \epsilon \log \epsilon
$$
此时，输入符号均匀分布，$p_{i} \equiv \cfrac{1}{M}$。

## 连续幅值信道

类似于离散幅值信道，**连续幅值信道 (continuous amplitude channel)** 也可以用条件概率密度函数 $p_{Y|X}(y, x)$ 来描述，所传递的信息量仍然用互信息 $I(X; Y)$ 来衡量。

若允许通过映射**调整输入分布 $p_{X}(x)$**，则可以在此意义下**最大化[[信源#微分熵的互信息|互信息]] $I(X;Y)$**，这一最大值仍然称为**信道容量 (channel capacity)**，记为
$$
C = \max\limits_{p_{X}(x)} I(X; Y)
$$

### Gauss 信道

**Gauss 信道 (Gaussian channel)** 是一种特殊的连续幅值信道，假设信道输出 $Y$ 是输入 $X$ 与高斯白噪声 $Z$ 的和，即
$$
Y = X + Z, \qquad \text{where} \quad Z \sim \mathcal{N}(0, \sigma^{2})
$$
其中 $X$ 有功率约束 $\mathbb{E}\left[ X^{2} \right] = E_{\mathrm{s}}$。

Gauss 信道的容量为
$$
\begin{align}
C &= \max\limits_{p_{X}(x)} I(X; Y) = \max\limits_{p_{X}(x)} I(X; X + Z) 
= \max\limits_{p_{X}(x)} \big( h(X + Z) - h(X + Z \mid X) \big) \\
&= \max\limits_{p_{X}(x)} \big( h(X + Z) - h(Z) \big) 
= \max\limits_{p_{X}(x)} h(X + Z) - \log \sqrt{ 2 \pi \e \sigma^{2} }
\end{align}
$$
因此，最大化互信息等价于**最大化 $h(X + Z)$**。由于 $X$、$Z$ 独立，
$$
\mathbb{E}\left[ (X + Z)^{2} \right] = \mathbb{E}\left[ X^{2} \right] + \mathbb{E}\left[ Z^{2} \right] + 2 \mathbb{E}\left[ X \right] \underbrace{ \mathbb{E}\left[ Z \right] }_{ 0 } = E_{\mathrm{s}} + \sigma^{2}
$$
当且仅当 $X \sim \mathcal{N}(0, E_{\mathrm{s}})$ 时，$X + Z \sim \mathcal{N}(0, E_{\mathrm{s}} + \sigma^{2})$，$h(X + Z)$ 最大化为
$$
h(X + Z) = \log \sqrt{ 2 \pi \e (E_{\mathrm{s}} + \sigma^{2}) }
$$
从而
$$
C = \log \sqrt{ 2\pi \e (E_{\mathrm{s}} + \sigma^{2}) } - \log \sqrt{ 2 \pi \e \sigma^{2} } = \mark{ \log \sqrt{ 1 + \dfrac{E_{\mathrm{s}}}{\sigma^{2}} } }
$$
这里 $C$ 无量纲，单位为 bit/次。

### 带宽受限的 Gauss 信道

在实际通信系统中，信道通常是**带宽受限 (bandwidth-limited)** 的，即信号只能在有限的频率范围内传输。设信道的带宽为 $W$，则根据 **Nyquist 采样定理**，单位时间最多可以传输 $2W$ 个独立符号。

考虑带宽受限为 $W$ 的 Gauss 信道，由于这一信道中的噪声是与信号**时域相加**的、功率谱在 $[-W,W]$ 均匀的 Gauss 噪声，因此称为**加性白 Gauss 噪声 (Additive White Gaussian Noise, AWGN) 信道**。设其中噪声 $N(t)$ 的方差为 $\sigma^{2}$，则
$$
R_{N}(t, s) = \begin{cases}
\mathbb{E}\left[ N^{2}(t) \right] = \sigma^{2}, & t = s \\
0, & t \neq s
\end{cases} = \sigma^{2} \delta(t - s)
$$
因此 $N(t)$ 是**宽平稳**的，$R_{N}(\tau) = \sigma^{2} \delta(\tau)$，其功率谱密度为
$$
S_{N}(f) = \int_{-\infty}^{+\infty} R_{N}(\tau) \e^{-j 2 \pi f \tau} \dif \tau = \sigma^{2}, \quad |f| \leq W
$$
将正负频部分合并，得到单边功率谱密度为
$$
S_{N}^{\text{(single)}}(f) = 2 \sigma^{2} =: n_{0}, \quad 0 \leq f \leq W
$$

同时，记通信功率 $P$ 为单位时间内传输的平均能量，则每个符号的平均能量为 $E_{\mathrm{s}} = \cfrac{P}{2W}$。则 AWGN 信道的容量为
$$
C = 2W \log \sqrt{ 1 + \dfrac{P}{2W \sigma^{2}} } = W \log \left( 1 + \dfrac{P}{Wn_{0}} \right)
$$

> [!theorem] Shannon 公式
> 带宽受限于 $|f| \le W$、噪声功率谱密度为 $S_{N}(f) = \dfrac{n_{0}}{2}$ 的 **AWGN 信道**在功率 $P$ 下的容量为
> $$
> C = {W} \log \left( 1 + \dfrac{P}{W n_{0}} \right)
> $$
> 其中 $C$ 的单位为 bit/s。

信号功率与噪声功率的比值 $\cfrac{P}{Wn_{0}}$ 称为**信噪比 (signal-to-noise ratio, SNR)**，可记为 $\mathrm{SNR}$。因此，Shannon 公式也可以写为
$$
C = W \log (1 + \mathrm{SNR})
$$
+ 当 $\mathrm{SNR} \to 0$ 时，即在**低 SNR** 区，
$$C \to W \log\e \cdot \mathrm{SNR} =\dfrac{P}{n_{0}}\log \e \approx 1.44 \dfrac{P}{n_{0}}$$
容量 $C$ 与带宽 $W$ 无关，而与功率 $P$ 呈线性关系；
+ 当 $\mathrm{SNR} \to +\infty$ 时，即在**高 SNR** 区，$C \to W \log \mathrm{SNR}$，引入信噪比的分贝值 $\mathrm{SNR}_{\mathrm{dB}} = 10 \log_{10} \mathrm{SNR} = \cfrac{10}{\log 10}\log \mathrm{SNR}$，则
$$
C \to W \cdot \dfrac{\log 10}{10} \mathrm{SNR}_{\mathrm{dB}} \approx 0.3322 W \cdot \mathrm{SNR}_{\mathrm{dB}}
$$

